{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee08212c-e9f7-4cce-b687-d0573dceb4ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-07-26 18:43:15--  https://dl.fbaipublicfiles.com/fairseq/models/bart.base.tar.gz\n",
      "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 108.157.4.81, 108.157.4.84, 108.157.4.14, ...\n",
      "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|108.157.4.81|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 422876945 (403M) [application/x-tar]\n",
      "Saving to: ‘bart.base.tar.gz’\n",
      "\n",
      "bart.base.tar.gz    100%[===================>] 403,29M  10,6MB/s    in 48s     \n",
      "\n",
      "2023-07-26 18:44:03 (8,33 MB/s) - ‘bart.base.tar.gz’ saved [422876945/422876945]\n",
      "\n",
      "bart.base/\n",
      "bart.base/dict.txt\n",
      "bart.base/NOTE\n",
      "bart.base/model.pt\n",
      "--2023-07-26 18:44:10--  https://dl.fbaipublicfiles.com/fairseq/models/roberta.base.tar.gz\n",
      "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 108.157.4.81, 108.157.4.14, 108.157.4.84, ...\n",
      "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|108.157.4.81|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 231160875 (220M) [application/gzip]\n",
      "Saving to: ‘roberta.base.tar.gz’\n",
      "\n",
      "roberta.base.tar.gz 100%[===================>] 220,45M  9,65MB/s    in 21s     \n",
      "\n",
      "2023-07-26 18:44:32 (10,3 MB/s) - ‘roberta.base.tar.gz’ saved [231160875/231160875]\n",
      "\n",
      "roberta.base/\n",
      "roberta.base/dict.txt\n",
      "roberta.base/model.pt\n",
      "roberta.base/NOTE\n",
      "--2023-07-26 18:44:34--  https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/encoder.json\n",
      "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 108.157.4.14, 108.157.4.16, 108.157.4.81, ...\n",
      "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|108.157.4.14|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1042301 (1018K) [text/plain]\n",
      "Saving to: ‘gpt2_bpe/encoder.json’\n",
      "\n",
      "encoder.json        100%[===================>]   1018K  --.-KB/s    in 0,1s    \n",
      "\n",
      "2023-07-26 18:44:34 (7,36 MB/s) - ‘gpt2_bpe/encoder.json’ saved [1042301/1042301]\n",
      "\n",
      "--2023-07-26 18:44:34--  http://gpt2_bpe/\n",
      "Resolving gpt2_bpe (gpt2_bpe)... failed: Temporary failure in name resolution.\n",
      "wget: unable to resolve host address ‘gpt2_bpe’\n",
      "FINISHED --2023-07-26 18:44:34--\n",
      "Total wall clock time: 0,3s\n",
      "Downloaded: 1 files, 1018K in 0,1s (7,36 MB/s)\n",
      "--2023-07-26 18:44:34--  https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/vocab.bpe\n",
      "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 108.157.4.84, 108.157.4.16, 108.157.4.14, ...\n",
      "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|108.157.4.84|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 456318 (446K) [text/plain]\n",
      "Saving to: ‘gpt2_bpe/vocab.bpe’\n",
      "\n",
      "vocab.bpe           100%[===================>] 445,62K  --.-KB/s    in 0,07s   \n",
      "\n",
      "2023-07-26 18:44:34 (6,62 MB/s) - ‘gpt2_bpe/vocab.bpe’ saved [456318/456318]\n",
      "\n",
      "--2023-07-26 18:44:34--  http://gpt2_bpe/\n",
      "Resolving gpt2_bpe (gpt2_bpe)... failed: Temporary failure in name resolution.\n",
      "wget: unable to resolve host address ‘gpt2_bpe’\n",
      "FINISHED --2023-07-26 18:44:34--\n",
      "Total wall clock time: 0,1s\n",
      "Downloaded: 1 files, 446K in 0,07s (6,62 MB/s)\n",
      "--2023-07-26 18:44:34--  https://dl.fbaipublicfiles.com/fairseq/gpt2_bpe/dict.txt\n",
      "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 108.157.4.84, 108.157.4.16, 108.157.4.14, ...\n",
      "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|108.157.4.84|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 603290 (589K) [text/plain]\n",
      "Saving to: ‘gpt2_bpe/dict.txt’\n",
      "\n",
      "dict.txt            100%[===================>] 589,15K  --.-KB/s    in 0,06s   \n",
      "\n",
      "2023-07-26 18:44:35 (9,13 MB/s) - ‘gpt2_bpe/dict.txt’ saved [603290/603290]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!bash download.sh downloaded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f84b7b5-73ba-4148-9eb3-dbb9baf107d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting protobuf==3.20.*\n",
      "  Using cached protobuf-3.20.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
      "\u001b[33mDEPRECATION: omegaconf 2.0.6 has a non-standard dependency specifier PyYAML>=5.1.*. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of omegaconf or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: distro-info 0.23ubuntu1 has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of distro-info or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: python-debian 0.1.36ubuntu1 has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of python-debian or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: tensorflow-gpu 2.11.0 has a non-standard dependency specifier platform_system!=\"Darwin\". pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of tensorflow-gpu or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: protobuf\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.23.4\n",
      "    Uninstalling protobuf-4.23.4:\n",
      "      Successfully uninstalled protobuf-4.23.4\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorboardx 2.6.1 requires protobuf>=4.22.3, but you have protobuf 3.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed protobuf-3.20.3\n"
     ]
    }
   ],
   "source": [
    "# !pip install protobuf==3.20.*\n",
    "# !export TF_ENABLE_ONEDNN_OPTS=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "934057f0-feee-46ef-a33f-f25174eda019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-26 18:44:55 | INFO | fairseq_cli.preprocess | Namespace(aim_repo=None, aim_run_hash=None, align_suffix=None, alignfile=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, azureml_logging=False, bf16=False, bpe=None, cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='downloaded_data/roberta-classifier/cmv/data-bin/input0', dict_only=False, empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_file=None, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, on_cpu_convert_precision=False, only_source=True, optimizer=None, padding_factor=8, plasma_path='/tmp/plasma', profile=False, quantization_config_path=None, reset_logging=False, scoring='bleu', seed=1, source_lang=None, srcdict='downloaded_data/gpt2_bpe/dict.txt', suppress_crashes=False, target_lang=None, task='translation', tensorboard_logdir=None, testpref=None, tgtdict=None, threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref='downloaded_data/roberta-classifier/cmv/train.bpe', use_plasma_view=False, user_dir=None, validpref='downloaded_data/roberta-classifier/cmv/valid.bpe', wandb_project=None, workers=60)\n",
      "2023-07-26 18:44:55 | INFO | fairseq_cli.preprocess | [None] Dictionary: 50264 types\n",
      "2023-07-26 18:44:57 | INFO | fairseq_cli.preprocess | [None] downloaded_data/roberta-classifier/cmv/train.bpe: 4068 sents, 151564 tokens, 0.0% replaced (by <unk>)\n",
      "2023-07-26 18:44:57 | INFO | fairseq_cli.preprocess | [None] Dictionary: 50264 types\n",
      "2023-07-26 18:44:59 | INFO | fairseq_cli.preprocess | [None] downloaded_data/roberta-classifier/cmv/valid.bpe: 627 sents, 22040 tokens, 0.0% replaced (by <unk>)\n",
      "2023-07-26 18:44:59 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to downloaded_data/roberta-classifier/cmv/data-bin/input0\n",
      "2023-07-26 18:45:02 | INFO | fairseq_cli.preprocess | Namespace(aim_repo=None, aim_run_hash=None, align_suffix=None, alignfile=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, azureml_logging=False, bf16=False, bpe=None, cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='downloaded_data/roberta-classifier/cmv/data-bin/label', dict_only=False, empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_file=None, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, on_cpu_convert_precision=False, only_source=True, optimizer=None, padding_factor=8, plasma_path='/tmp/plasma', profile=False, quantization_config_path=None, reset_logging=False, scoring='bleu', seed=1, source_lang=None, srcdict=None, suppress_crashes=False, target_lang=None, task='translation', tensorboard_logdir=None, testpref=None, tgtdict=None, threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref='downloaded_data/roberta-classifier/cmv/train.label', use_plasma_view=False, user_dir=None, validpref='downloaded_data/roberta-classifier/cmv/valid.label', wandb_project=None, workers=60)\n",
      "2023-07-26 18:45:02 | INFO | fairseq_cli.preprocess | [None] Dictionary: 8 types\n",
      "2023-07-26 18:45:03 | INFO | fairseq_cli.preprocess | [None] downloaded_data/roberta-classifier/cmv/train.label: 4068 sents, 8136 tokens, 0.0% replaced (by <unk>)\n",
      "2023-07-26 18:45:03 | INFO | fairseq_cli.preprocess | [None] Dictionary: 8 types\n",
      "2023-07-26 18:45:03 | INFO | fairseq_cli.preprocess | [None] downloaded_data/roberta-classifier/cmv/valid.label: 627 sents, 1254 tokens, 0.0% replaced (by <unk>)\n",
      "2023-07-26 18:45:03 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to downloaded_data/roberta-classifier/cmv/data-bin/label\n",
      "Data in downloaded_data/cmv has finished preprocessing, and the final output is in downloaded_data/roberta-classifier/cmv/data-bin\n"
     ]
    }
   ],
   "source": [
    "!bash roberta-classifier/preprocess-roberta-classifier.sh downloaded_data cmv dm1-app dm2-inapp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72113457-2d78-4e70-9b87-607e3ed66307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-07-27 16:12:17 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': 'downloaded_data/roberta-classifier/cmv/tensorboard', 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 4, 'fp16_scale_window': 128, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': 1.0, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 8192, 'batch_size': 64, 'required_batch_size_multiple': 1, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 8192, 'batch_size_valid': 64, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 10, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [1e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': 'downloaded_data/roberta-classifier/cmv/checkpoints', 'restore_file': 'downloaded_data/roberta.base/model.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'accuracy', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='roberta_base', activation_dropout=0.0, activation_fn='gelu', adam_betas='(0.9, 0.98)', adam_eps=1e-06, adaptive_input=False, add_prev_output_tokens=False, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='roberta_base', attention_dropout=0.1, azureml_logging=False, batch_size=64, batch_size_valid=64, best_checkpoint_metric='accuracy', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', classification_head_name='classification_head', clip_norm=0.0, combine_valid_subsets=None, continue_once=None, cpu=False, cpu_offload=False, criterion='sentence_prediction', curriculum=0, d2v2_multi=False, data='downloaded_data/roberta-classifier/cmv/data-bin', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', debug_param_names=False, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.1, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=12, encoder_embed_dim=768, encoder_ffn_embed_dim=3072, encoder_layerdrop=0, encoder_layers=12, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=False, end_learning_rate=0.0, eos=2, fast_stat_sync=False, ffn_blocks_to_remove=-1, ffn_reg_scale_factor=0.0, find_unused_parameters=True, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=4, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=128, fp32_reduce_scatter=False, gen_subset='test', gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_unused_valid_subsets=False, init_token=0, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, layernorm_embedding=True, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lr=[1e-05], lr_scheduler='polynomial_decay', max_epoch=10, max_positions=512, max_source_positions=512, max_tokens=8192, max_tokens_valid=8192, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=False, mha_heads_to_keep=-1, mha_reg_scale_factor=0.0, min_loss_scale=0.0001, min_params_to_wrap=100000000, model_parallel_size=1, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=True, no_seed_provided=False, no_shuffle=False, no_token_positional_embeddings=False, not_fsdp_flatten_parameters=False, nprocs_per_node=1, num_classes=2, num_shards=1, num_workers=1, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', pooler_activation_fn='tanh', pooler_dropout=0.0, power=1.0, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, regression_target=False, report_acc_and_f1=False, report_mcc=False, report_pearson_and_spearman=False, required_batch_size_multiple=1, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=False, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, restore_file='downloaded_data/roberta.base/model.pt', save_dir='downloaded_data/roberta-classifier/cmv/checkpoints', save_interval=1, save_interval_updates=0, scoring='bleu', seed=1, sentence_avg=False, separator_token=2, shard_id=0, shorten_data_split_list='', shorten_method='truncate', skip_invalid_size_inputs_valid_test=False, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, spectral_norm_classification_head=False, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, task='sentence_prediction', tensorboard_logdir='downloaded_data/roberta-classifier/cmv/tensorboard', threshold_loss_scale=1.0, tokenizer=None, total_num_update='10000', tpu=False, train_subset='train', unk=3, untie_weights_roberta=False, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, use_bmuf=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_updates=469, weight_decay=0.1, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'sentence_prediction', 'data': 'downloaded_data/roberta-classifier/cmv/data-bin', 'num_classes': 2, 'init_token': 0, 'separator_token': 2, 'no_shuffle': False, 'shorten_method': truncate, 'shorten_data_split_list': '', 'add_prev_output_tokens': False, 'max_positions': 512, 'regression_target': False, 'classification_head_name': 'classification_head', 'seed': 1, 'd2v2_multi': False}, 'criterion': {'_name': 'sentence_prediction', 'classification_head_name': 'classification_head', 'regression_target': False, 'report_mcc': False, 'report_acc_and_f1': False, 'report_pearson_and_spearman': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-06, 'weight_decay': 0.1, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [1e-05]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 469, 'force_anneal': None, 'end_learning_rate': 0.0, 'power': 1.0, 'total_num_update': 10000.0, 'lr': [1e-05]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-07-27 16:12:17 | INFO | fairseq.tasks.sentence_prediction | [input] dictionary: 50265 types\n",
      "2023-07-27 16:12:17 | INFO | fairseq.tasks.sentence_prediction | [label] dictionary: 9 types\n",
      "2023-07-27 16:12:20 | INFO | fairseq_cli.train | RobertaModel(\n",
      "  (encoder): RobertaEncoder(\n",
      "    (sentence_encoder): TransformerEncoder(\n",
      "      (dropout_module): FairseqDropout()\n",
      "      (embed_tokens): Embedding(50265, 768, padding_idx=1)\n",
      "      (embed_positions): LearnedPositionalEmbedding(514, 768, padding_idx=1)\n",
      "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (layers): ModuleList(\n",
      "        (0-11): 12 x TransformerEncoderLayerBase(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (dropout_module): FairseqDropout()\n",
      "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (activation_dropout_module): FairseqDropout()\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (lm_head): RobertaLMHead(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (classification_heads): ModuleDict(\n",
      "    (classification_head): RobertaClassificationHead(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "      (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "2023-07-27 16:12:20 | INFO | fairseq_cli.train | task: SentencePredictionTask\n",
      "2023-07-27 16:12:20 | INFO | fairseq_cli.train | model: RobertaModel\n",
      "2023-07-27 16:12:20 | INFO | fairseq_cli.train | criterion: SentencePredictionCriterion\n",
      "2023-07-27 16:12:20 | INFO | fairseq_cli.train | num. shared model params: 125,288,795 (num. trained: 125,288,795)\n",
      "2023-07-27 16:12:20 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n",
      "2023-07-27 16:12:20 | INFO | fairseq.data.data_utils | loaded 627 examples from: downloaded_data/roberta-classifier/cmv/data-bin/input0/valid\n",
      "2023-07-27 16:12:20 | INFO | fairseq.data.data_utils | loaded 627 examples from: downloaded_data/roberta-classifier/cmv/data-bin/label/valid\n",
      "2023-07-27 16:12:20 | INFO | fairseq.tasks.sentence_prediction | Loaded valid with #samples: 627\n",
      "2023-07-27 16:12:21 | INFO | fairseq.trainer | detected shared parameter: encoder.sentence_encoder.embed_tokens.weight <- encoder.lm_head.weight\n",
      "2023-07-27 16:12:21 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
      "2023-07-27 16:12:21 | INFO | fairseq_cli.train | max tokens per device = 8192 and max sentences per device = 64\n",
      "2023-07-27 16:12:21 | INFO | fairseq.trainer | Preparing to load checkpoint downloaded_data/roberta.base/model.pt\n",
      "2023-07-27 16:12:23 | INFO | fairseq.models.roberta.model | Overwriting classification_heads.classification_head.dense.weight\n",
      "2023-07-27 16:12:23 | INFO | fairseq.models.roberta.model | Overwriting classification_heads.classification_head.dense.bias\n",
      "2023-07-27 16:12:23 | INFO | fairseq.models.roberta.model | Overwriting classification_heads.classification_head.out_proj.weight\n",
      "2023-07-27 16:12:23 | INFO | fairseq.models.roberta.model | Overwriting classification_heads.classification_head.out_proj.bias\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/shady/Environments/miniconda3/envs/lewis/bin/fairseq-train\", line 8, in <module>\n",
      "    sys.exit(cli_main())\n",
      "  File \"/home/shady/Projects/fairseq/fairseq_cli/train.py\", line 574, in cli_main\n",
      "    distributed_utils.call_main(cfg, main)\n",
      "  File \"/home/shady/Projects/fairseq/fairseq/distributed/utils.py\", line 404, in call_main\n",
      "    main(cfg, **kwargs)\n",
      "  File \"/home/shady/Projects/fairseq/fairseq_cli/train.py\", line 165, in main\n",
      "    extra_state, epoch_itr = checkpoint_utils.load_checkpoint(\n",
      "  File \"/home/shady/Projects/fairseq/fairseq/checkpoint_utils.py\", line 255, in load_checkpoint\n",
      "    extra_state = trainer.load_checkpoint(\n",
      "  File \"/home/shady/Projects/fairseq/fairseq/trainer.py\", line 642, in load_checkpoint\n",
      "    self.lr_step(epoch)\n",
      "  File \"/home/shady/Projects/fairseq/fairseq/trainer.py\", line 1203, in lr_step\n",
      "    self.lr_scheduler.step(epoch, val_loss)\n",
      "  File \"/home/shady/Projects/fairseq/fairseq/trainer.py\", line 286, in lr_scheduler\n",
      "    self._build_optimizer()  # this will initialize self._lr_scheduler\n",
      "  File \"/home/shady/Projects/fairseq/fairseq/trainer.py\", line 338, in _build_optimizer\n",
      "    self._optimizer = optim.FP16Optimizer.build_optimizer(self.cfg, params)\n",
      "  File \"/home/shady/Projects/fairseq/fairseq/optim/fp16_optimizer.py\", line 301, in build_optimizer\n",
      "    fp32_params = cls.build_fp32_params(cfg.optimizer, params, flatten=flatten)\n",
      "  File \"/home/shady/Projects/fairseq/fairseq/optim/fp16_optimizer.py\", line 38, in build_fp32_params\n",
      "    devices = [torch.cuda.current_device()]\n",
      "  File \"/home/shady/Environments/miniconda3/envs/lewis/lib/python3.8/site-packages/torch/cuda/__init__.py\", line 674, in current_device\n",
      "    _lazy_init()\n",
      "  File \"/home/shady/Environments/miniconda3/envs/lewis/lib/python3.8/site-packages/torch/cuda/__init__.py\", line 239, in _lazy_init\n",
      "    raise AssertionError(\"Torch not compiled with CUDA enabled\")\n",
      "AssertionError: Torch not compiled with CUDA enabled\n"
     ]
    }
   ],
   "source": [
    "!bash roberta-classifier/train-roberta-classifier.sh downloaded_data cmv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c2d1656f-6ef2-431f-8f20-2e173ec45fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!bash lewis/bart-denoising/preprocess-bart-denoising.sh lewis/downloaded_data cmv dm1-app\n",
    "!bash lewis/bart-denoising/preprocess-bart-denoising.sh lewis/downloaded_data cmv dm2-inapp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "91f3de32-a6aa-407d-9bf6-6451f8a59785",
   "metadata": {},
   "outputs": [],
   "source": [
    "!bash lewis/bart-denoising/train-bart-denoising.sh lewis/downloaded_data cmv dm1-app\n",
    "!bash lewis/bart-denoising/train-bart-denoising.sh lewis/downloaded_data cmv dm2-inapp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892e75c5-ba08-4bb2-879e-01d98ee24a9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
